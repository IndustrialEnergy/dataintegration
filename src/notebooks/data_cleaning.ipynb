{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import janitor\n",
    "from janitor import clean_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------- define paths -------\n",
    "# define relative path\n",
    "relative_path = Path('../../data/raw_data/')\n",
    "\n",
    "# get absolute path\n",
    "absolute_path = relative_path.resolve()\n",
    "print(absolute_path)\n",
    "\n",
    "# declare file names\n",
    "filename_iac = \"IAC_Database_20250208.xls\"\n",
    "filename_ppi = \"ARC_PPI_EM_16Apr2025_v2.xlsx\"\n",
    "filename_generation = \"annual_generation_state.xls\"\n",
    "filename_emissions = \"emission_annual.xlsx\"\n",
    "\n",
    "# ------- import data -------\n",
    "\n",
    "# import IAC database\n",
    "iac_df = pd.read_excel(absolute_path/filename_iac, sheet_name=None)\n",
    "# import all RECC* sheets from the IAC database excel file  \n",
    "all_sheets = pd.read_excel(absolute_path/filename_iac, sheet_name=None) \n",
    "# filter sheets that match the pattern\n",
    "recc_sheets = {name: data for name, data in all_sheets.items() if name.startswith('RECC')}\n",
    "# combine matching sheets into a single DataFrame\n",
    "iac_recc_df = pd.concat(\n",
    "    [sheet.assign(RECC=name) for name, sheet in recc_sheets.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# import ASSESS table\n",
    "iac_assess_df = all_sheets['ASSESS']\n",
    "\n",
    "# import PPI sheet\n",
    "ppi_df = pd.read_excel(absolute_path/filename_ppi, sheet_name=\"ppi\", skiprows=6, dtype={\"ARC\": str})\n",
    "\n",
    "# import Electricity Generation table\n",
    "generation_df = pd.read_excel(absolute_path/filename_generation, sheet_name=\"Net_Generation_1990-2023 Final\", skiprows=1)\n",
    "\n",
    "# import Electricity Emissions table\n",
    "emissions_df = pd.read_excel(absolute_path/filename_emissions, sheet_name=\"State Emissions\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the iac_recc table from wide to long format\n",
    "\n",
    "Requirements\n",
    "1. Keep all common columns\n",
    "2. Create four rows for each input row (one for each energy source usage ranking: Primary, Secondary, Tertiary, Quaternary)\n",
    "3. Maintain the relationship between energy source codes and their associated values: SOURCCODE, CONSERVED, SOURCONSV, SAVED\n",
    "4. Order the columns to maintain the original dataframe structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a function to trasnform the recc table from wide to long format\n",
    "def transform_recc_data(df):\n",
    "    \"\"\"\n",
    "    Transform wide format usage data to long format by unpivoting usage-related columns.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame in wide format\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Transformed DataFrame in long format\n",
    "    \"\"\"\n",
    "    \n",
    "    # Common columns that will be repeated for each usage record\n",
    "    common_cols = ['SUPERID', 'ID', 'AR_NUMBER', 'APPCODE', 'ARC2', \n",
    "                  'IMPSTATUS', 'IMPCOST', 'REBATE', 'INCREMNTAL', \n",
    "                  'FY', 'IC_CAPITAL', 'IC_OTHER', 'PAYBACK', 'BPTOOL']\n",
    "    \n",
    "    # Create list of usage types\n",
    "    usage_types = ['P', 'S', 'T', 'Q']\n",
    "    \n",
    "    # Initialize list to store transformed data\n",
    "    transformed_data = []\n",
    "    \n",
    "    # Iterate through each row in the original dataframe\n",
    "    for _, row in df.iterrows():\n",
    "        # For each usage type, create a new record\n",
    "        for usage in usage_types:\n",
    "            new_row = {col: row[col] for col in common_cols}\n",
    "            \n",
    "            # Add usage-specific columns\n",
    "            sourccode_col = f'{usage}SOURCCODE'\n",
    "            conserved_col = f'{usage}CONSERVED'\n",
    "            sourconsv_col = f'{usage}SOURCONSV'\n",
    "            saved_col = f'{usage}SAVED'\n",
    "            \n",
    "            new_row['SOURCE_RANK'] = f'{usage}SOURCCODE'\n",
    "            new_row['SOURCCODE'] = row.get(sourccode_col, '')\n",
    "            new_row['CONSERVED'] = row.get(conserved_col, '')\n",
    "            new_row['SOURCONSV'] = row.get(sourconsv_col, '')\n",
    "            new_row['SAVED'] = row.get(saved_col, '')\n",
    "            \n",
    "            transformed_data.append(new_row)\n",
    "    \n",
    "    # Create new dataframe from transformed data\n",
    "    result_df = pd.DataFrame(transformed_data)\n",
    "    \n",
    "    # Ensure columns are in the desired order\n",
    "    column_order = common_cols[:7] + ['SOURCE_RANK', 'SOURCCODE', 'CONSERVED', \n",
    "                                    'SOURCONSV', 'SAVED'] + common_cols[7:]\n",
    "    \n",
    "    return result_df[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform recc dataset from wide to long\n",
    "iac_recc_tidy_df = transform_recc_data(iac_recc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify transformed data\n",
    "filtered_df = iac_recc_tidy_df.query('SUPERID in [\"AM000202\",\"AM000504\"]')\n",
    "filtered_df\n",
    "\n",
    "sample_recc_df = filtered_df[['SUPERID', 'ID', 'AR_NUMBER','IMPSTATUS', 'IMPCOST',\n",
    "       'SOURCE_RANK', 'SOURCCODE', 'CONSERVED', \n",
    "                                    'SOURCONSV', 'SAVED']]\n",
    "sample_recc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the iac_assess table from wide to long format\n",
    "\n",
    "Requirements\n",
    "1. Keep all common columns\n",
    "2. Convert *_plant_usage and *_plant_cost columns into rows under the plant_usage and plant_cost columns, and add a separate column for the source code.\n",
    "4. Order the columns to maintain the original dataframe structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_assess_data(df):\n",
    "    \"\"\"\n",
    "    Transform wide format plant data to long format by converting *_plant_usage \n",
    "    and *_plant_cost columns into rows.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame in wide format\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Transformed DataFrame in long format\n",
    "    \"\"\"\n",
    "    # Common columns that will be preserved\n",
    "    id_vars = ['CENTER', 'FY', 'SIC', 'NAICS', 'STATE', 'SALES', \n",
    "               'EMPLOYEES', 'PLANT_AREA', 'PRODUCTS', 'PRODUNITS', \n",
    "               'PRODLEVEL', 'PRODHOURS', 'NUMARS']\n",
    "    \n",
    "    # Melt cost columns\n",
    "    cost_df = pd.melt(\n",
    "        df,\n",
    "        id_vars=['ID'] + id_vars,\n",
    "        value_vars=[col for col in df.columns if col.endswith('_plant_cost')],\n",
    "        var_name='source_code',\n",
    "        value_name='plant_cost'\n",
    "    )\n",
    "    # Clean up source_code by removing '_plant_cost'\n",
    "    cost_df['source_code'] = cost_df['source_code'].str.replace('_plant_cost', '')\n",
    "    \n",
    "    # Melt usage columns\n",
    "    usage_df = pd.melt(\n",
    "        df,\n",
    "        id_vars=['ID'] + id_vars,\n",
    "        value_vars=[col for col in df.columns if col.endswith('_plant_usage')],\n",
    "        var_name='source_code',\n",
    "        value_name='plant_usage'\n",
    "    )\n",
    "    # Clean up source_code by removing '_plant_usage'\n",
    "    usage_df['source_code'] = usage_df['source_code'].str.replace('_plant_usage', '')\n",
    "    \n",
    "    # Merge cost and usage dataframes\n",
    "    result_df = cost_df.merge(\n",
    "        usage_df,\n",
    "        on=['ID'] + id_vars + ['source_code'],\n",
    "        how='outer'\n",
    "    )\n",
    "    \n",
    "    # Create ordered categorical for source_code\n",
    "    source_order = ['EC', 'ED', 'EF'] + [f'E{i}' for i in range(2, 13)] + [f'W{i}' for i in range(7)]\n",
    "    result_df['source_code'] = pd.Categorical(result_df.source_code, categories=source_order, ordered=True)\n",
    "    \n",
    "    # Remove rows where both plant_cost and plant_usage are NA\n",
    "    result_df = result_df.dropna(subset=['plant_cost', 'plant_usage'], how='all')\n",
    "\n",
    "    # Sort by ID and source_code and set ID as index\n",
    "    # result_df = result_df.sort_values(by=['ID', 'source_code']).set_index('ID')\n",
    "    result_df = result_df.sort_values(by=['ID', 'source_code'])\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform assess dataset from wide to long\n",
    "iac_assess_tidy_df = transform_assess_data(iac_assess_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify transformed data\n",
    "sample_assess_df = iac_assess_tidy_df.query('ID in [\"AM0002\",\"AM0005\",\"AM0324\"]')\n",
    "sample_assess_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the ppi table from wide to long format\n",
    "\n",
    "Requirements\n",
    "1. Keep all common columns\n",
    "2. Convert year columns into rows under the year and ppi columns\n",
    "4. Order the columns to maintain the original dataframe structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select columns that are integers >= 1990\n",
    "year_columns = [col for col in ppi_df.columns if isinstance(col, int) and col >= 1990]\n",
    "\n",
    "#ppi_tidy_df = transform_ppi_data(ppi_df)\n",
    "ppi_tidy_df = pd.melt(\n",
    "    ppi_df,\n",
    "    id_vars=['ARC', 'Description', 'Series ID', 'Industry', 'Product'],\n",
    "    value_vars=year_columns,\n",
    "    var_name='year',\n",
    "    value_name='ppi'\n",
    "    )\n",
    "\n",
    "ppi_tidy_df = ppi_tidy_df.sort_values(by=['year', 'ARC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify transformed data\n",
    "ppi_tidy_df.head(-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the emissions table from wide to long format\n",
    "\n",
    "Requirements\n",
    "1. Keep all common columns\n",
    "2. Convert emission type columns into rows under the emission type columns and emissions columns\n",
    "3. Add a column for units\n",
    "4. Order the columns to maintain the original dataframe structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emissions_df.columns = [col.replace('\\n(Metric Tons)', '') \n",
    "                        for col in emissions_df.columns]\n",
    "# Melt the dataframe\n",
    "emissions_tidy_df = pd.melt(\n",
    "    emissions_df,\n",
    "    id_vars = ['State', 'Year', 'Producer Type', 'Energy Source'],\n",
    "    value_vars = ['CO2', 'SO2', 'NOx'],\n",
    "    var_name = 'emission_type',\n",
    "    value_name = 'amount'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify transformed data\n",
    "emissions_tidy_df.head(-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------ Clean data: ASSESS table ------------------------#\n",
    "\n",
    "iac_assess_tidy_df = iac_assess_tidy_df.clean_names()\n",
    "# strip whitespace from all string columns\n",
    "for col in iac_assess_tidy_df.select_dtypes(include='object').columns:\n",
    "    iac_assess_tidy_df[col] = iac_assess_tidy_df[col].str.strip()\n",
    "\n",
    "#------------------------ Clean RECC table ------------------------#\n",
    "\n",
    "# Replace old source coce for electricity values \"E1\" with \"EC\"\n",
    "# Reason: E1 was replaced with EC, ED, and EF as of FY 95 (9/30/95)\n",
    "# Reference: https://iac.university/technicalDocs/IAC_DatabaseManualv10.2.pdf\n",
    "iac_recc_tidy_df.replace({'SOURCCODE':{'E1':'EC'}}, inplace=True)\n",
    "iac_recc_tidy_df = iac_recc_tidy_df.clean_names()\n",
    "\n",
    "#------------------------ Clean PPI table ------------------------#\n",
    "\n",
    "ppi_tidy_df.rename(columns={'ARC': 'ARC2'}, inplace=True) # rename the column ARC to ARC2\n",
    "ppi_tidy_df['ARC2'] = pd.to_numeric(ppi_tidy_df['ARC2'], errors='coerce')\n",
    "ppi_tidy_df['ppi'] = pd.to_numeric(ppi_tidy_df['ppi'], errors='coerce')\n",
    "ppi_tidy_df = ppi_tidy_df.clean_names()\n",
    "# round ARC values to 4 decimal places\n",
    "ppi_tidy_df['arc2'] = ppi_tidy_df['arc2'].round(4)\n",
    "ppi_tidy_df['ppi'] = ppi_tidy_df['ppi'].round(2)\n",
    "\n",
    "#------------------------  Clean data: Electricity Generation table ------------------------#\n",
    "\n",
    "generation_df = generation_df.rename(columns={'generation_megawatthours_': 'generation_megawatthours'})\n",
    "generation_df['units'] = 'MWh' # add a column for units\n",
    "generation_df = generation_df.clean_names()\n",
    "# strip whitespace from all string columns\n",
    "for col in generation_df.select_dtypes(include='object').columns:\n",
    "    generation_df[col] = generation_df[col].str.strip()\n",
    "\n",
    "#------------------------ Clean data: Electricity Emissions table ------------------------#\n",
    "\n",
    "emissions_tidy_df = emissions_tidy_df.clean_names()\n",
    "# strip whitespace from all string columns\n",
    "for col in emissions_tidy_df.select_dtypes(include='object').columns:\n",
    "   emissions_tidy_df[col] = emissions_tidy_df[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test PPI data output\n",
    "len(ppi_tidy_df[ppi_tidy_df['arc2']==2.7142]) # 35 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ppi_tidy_df[ppi_tidy_df['arc2']==2.1123]\n",
    "ppi_tidy_df['ppi'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IAC assess clean data\n",
    "iac_assess_tidy_df.to_csv(\"../../data/intermediate_data/iac_assess_tidy.csv\", index=False)\n",
    "# IAC recc clean data\n",
    "iac_recc_tidy_df.to_csv(\"../../data/intermediate_data/iac_recc_tidy.csv\", index=False)\n",
    "# PPI clean data\n",
    "ppi_tidy_df.to_csv(\"../../data/intermediate_data/ppi_tidy.csv\", index=False)\n",
    "# Generation clean data\n",
    "generation_df.to_csv(\"../../data/intermediate_data/generation.csv\", index=False)\n",
    "# Emissions clean data\n",
    "emissions_tidy_df.to_csv(\"../../data/intermediate_data/emissions_tidy.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eds220-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
